%!TEX TS-program = pdflatex or xelatex
%!TEX encoding = UTF-8 Unicode

\documentclass{article}
\usepackage[letterpaper, top=1in, left=0.75in, right=0.75in, bottom=0.75in] {geometry}
\usepackage{microtype} % micro appearance
\usepackage[all]{nowidow} % no lone lines
\usepackage{changepage} % changes layout mid-page
\usepackage{enumitem} % enum (itemize, enumerate, description)
\usepackage{ifthen}
\usepackage{xfrac}
\usepackage{fancyhdr} % headers
\usepackage{amsmath} % matrices
\usepackage{amssymb} % symbols
\usepackage{relsize}
\usepackage{gensymb} % symbols
\usepackage{tikz} % graphics?
\usepackage{bm} % bold math
\usepackage{multicol} % multiple columns
\usepackage{lipsum} % lipsum

\pagestyle{fancy}

\newcommand {\classname} {CS 4740/5740 -- Intro to Natural Language Processing}
\newcommand {\duedate} {Tue, 2014--04--15}
\newcommand {\hwtype} {Project}
\newcommand {\hwnum} {3 (proposal)}
\newcommand {\innermargin} {0.15in} % indentation amt of nested lst

\let\tss\textsuperscript
\let\oldunderline\underline
\renewcommand\underline[1]{\oldunderline{\smash{#1}}}

\fancyhead[L] {\ifthenelse {\thepage=1}
  {bgs53 (Ben Shulman), sg754 (Spandana Govindgari),\\
   ms969 (MJ Sun), amw275 (Andy Wang)}
  {\hwtype\ \hwnum\ (bgs53, sg754, ms969, amw275)}}
\fancyhead[R] {\ifthenelse {\thepage=1}
  {\classname\\\hwtype\ \hwnum\ (due \duedate)}
  {Page \thepage}}

\begin{document}
\begin{center}\textbf{Project 3: Sequence tagging; Sentiment Classification -- Proposal}\end{center}

Our code will be written in Python.

\subsection*{Our sequence-tagging system}

\textit{Describe your sequence-tagging system.}\par

\begin{itemize}
\item \textit{Which model are you planning to implement?}\par

We are not initially going to implement MEMMs as our sequence tagging system; we will implement HMMs. We do not plan on using HMM libraries, but instead will write our own. [elaborate on data structure and provide code?]

We plan on having two baselines. One will use the following algorithm: from the training data we will record how many times each word occurs in a positive, neutral or negative sentence. Using that we can estimate the probability of a sentence's sentiment. For each word in the sentence we pull its probability for each sentiment and multiply it into the probability for each sentiment. Thus we perform the following equation to classify the sentence, where $S$ is the set of sentiments and the sentence has $n$ tokens:
\[argmax_{s \in S}{\prod_{i=1}^n} P(s|w_i).\]

The other baseline can simply be choosing positive / negative / neutral randomly given any sentence, possibly based on the frequency of positive / neg / neutral items we have in training.

\item \textit{Explain the algorithmic key points of your model. (Hidden variables \& observed variables for our setting, model parameters)}\par

Our hidden variables are the sentiments (-1, 0, 1). Our observed variables are the feature vectors of sentences. Our HMM Model will take in a set of tags (sentiments), a transition probability matrix, an emission matrix, the start state and what n-gram model to use. By n-gram model we mean, is the transmission matrix bi-gram, tri-gram, etc.

\item \textit{Brainstorm which features you would incorporate to learn emission probabilities. Support your design decisions based on the real examples given
in the dataset.}\par

Since there are so many possible sentences, and the chance of seeing an exact sentence is very small, we need to represent the sentences in general but meaningful ways to maximize the usefulness of the HMM. One representation of sentences is to count the number of positive, negative, and neutral words in the sentence and have these 3 counts as a \emph{feature vector}. Whether a word is positive, negative, or neutral is calculated by \emph{counting the percentage of times that word appears} in a negative sentence, positive sentence, and neutral sentence and pick the sentiment that the word appear most in.

An extension of this is to use sentiment lexicons to label the sentiment of each word instead of calculating the sentiment from the training data. The one lexicon we're looking at, SentiWordNet, assigns sentiments to each sense of of each word, since we want to avoid the complexity of doing sense calculations, we can choose the most frequent sentiment associated with the word across all of its senses.

An additional feature can be a positivity score for the sentence. Some lexicons give positivity and negativity scores. We can add the positivity score of each word subtracted by the negativity score of each word to obtain a general score of the sentence and use that as an additional feature.

All these metrics will have to be bucketed to limit the size of the feature set since we do not have a lot of data. The size of the bucket will be a parameter that we can tune with a validation set. Smoothing will probably also help with zeros in the feature space.
\end{itemize}

\subsection*{Progress so far}
Currently, we have parsed \texttt{training\_data.txt} into memory using Python and NLTK. Our parser, \texttt{getReviewList}, in \texttt{parseReviews.py}, returns a list of reviews whose sentences have been lemmatized and have English stopwords removed. [provide code?]

\end{document}
