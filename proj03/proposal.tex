%!TEX TS-program = pdflatex or xelatex
%!TEX encoding = UTF-8 Unicode

\documentclass{article}
\usepackage[letterpaper, top=1in, left=0.75in, right=0.75in, bottom=0.75in] {geometry}
\usepackage{microtype} % micro appearance
\usepackage[all]{nowidow} % no lone lines
\usepackage{changepage} % changes layout mid-page
\usepackage{enumitem} % enum (itemize, enumerate, description)
\usepackage{ifthen}
\usepackage{xfrac}
\usepackage{fancyhdr} % headers
\usepackage{amsmath} % matrices
\usepackage{amssymb} % symbols
\usepackage{relsize}
\usepackage{gensymb} % symbols
\usepackage{tikz} % graphics?
\usepackage{bm} % bold math
\usepackage{multicol} % multiple columns
\usepackage{lipsum} % lipsum

\pagestyle{fancy}

\newcommand {\classname} {CS 4740/5740 -- Intro to Natural Language Processing}
\newcommand {\duedate} {Tue, 2014--04--15}
\newcommand {\hwtype} {Project}
\newcommand {\hwnum} {3 (proposal)}
\newcommand {\innermargin} {0.15in} % indentation amt of nested lst

\let\tss\textsuperscript
\let\oldunderline\underline
\renewcommand\underline[1]{\oldunderline{\smash{#1}}}

\fancyhead[L] {\ifthenelse {\thepage=1}
  {bgs53 (Ben Shulman), sg754 (Spandana Govindgari),\\
   ms969 (MJ Sun), amw275 (Andy Wang)}
  {\hwtype\ \hwnum\ (bgs53, sg754, ms969, amw275)}}
\fancyhead[R] {\ifthenelse {\thepage=1}
  {\classname\\\hwtype\ \hwnum\ (due \duedate)}
  {Page \thepage}}

\begin{document}
\begin{center}\textbf{Project 3: Sequence tagging; Sentiment Classification -- Proposal}\end{center}

\subsection*{Our sequence-tagging system}

\textit{Describe your sequence-tagging system.}\par

\begin{itemize}
\item Which model are you planning to implement?\par

We will implement HMMs as our sequence tagging system. (We may also attempt the MEMMs model.) We are not planning on using existing Python libraries that provide implementations of HMMs because we think they are difficult to fine-tune for testing.

We plan on having two baselines. One will use the following algorithm: from the training data we will record how many times each word occurs in a positive, neutral or negative sentence. Using that we can estimate the probability of a sentence's sentiment. For each word in the sentence we pull its probability for each sentiment and multiply it into the probability for each sentiment. Thus we perform the following equation to classify the sentence, where $S$ is the set of sentiments and the sentence has $n$ tokens:
\[argmax_{s \in S}{\prod_{i=1}^n} P(s|w_i).\]

Another trivial baseline we may use can simply be choosing positive / negative / neutral randomly given any sentence, possibly weighted by the frequency of positive / neg / neutral sequences we have in training.

\item Explain the algorithmic key points of your model. (Hidden variables \& observed variables for our setting, model parameters)\par

Our hidden variables are the sentiments (-1, 0, 1). Our observed variables are the feature vectors of sentences. Our HMM Model will take in a set of tags (sentiments), a transition probability matrix, an emission matrix, the start state, and what n-gram model to use (e.g., is the transition matrix a bigram/trigram/etc.). We will implement an HMM is a python class that stores eachs of its inputs and then uses Viterbi's algorithm to tag test documents. We may, if feeling ambitious, extend our HMM to take arbitrary training data and calculate the necessary data to create the model.

\item Brainstorm which features you would incorporate to learn emission probabilities. Support your design decisions based on the real examples given in the dataset.\par

Sentences are numerous! The chance of seeing an exact sentence is very small, so meaningful sentence representation is crucial for the HMM. One representation is to count the number of positive, negative, and neutral words in the sentence and have these 3 counts as a \emph{feature vector}. Whether a word is positive, negative, or neutral is calculated by \emph{counting the percentage of times that word appears} in a negative/positive/neutral sentence and pick the sentiment that the word appear most in. In the lexicon, we note that those sentences with the word ``good'' tend to be positive: \emph{``\ldots BUT it is a good one.''}

An extension of this is to use sentiment lexicons to label the sentiment of each word instead of calculating the sentiment from the training data. One lexicon, SentiWordNet, assigns sentiments to each sense of of each word. To avoid the complexity of doing sense calculations, we can choose the most frequent sentiment associated with the word across all of its senses.

An additional feature is the \emph{positivity score} for the sentence, provided by some lexicons. We can add the positivity score minus the negativity score of each word to obtain a general score.

These metrics will be bucketed to limit the size of the feature set since we do not have a lot of data. Smoothing will probably also help with zeros in the feature space.
\end{itemize}

\subsection*{Progress so far}
Currently, we have parsed \texttt{training\_data.txt} into memory using Python and NLTK. Our parser, \texttt{getReviewList}, returns a list of reviews whose sentences have been lemmatized and have English stopwords removed.

\begin{verbatim}
sentiment = strToSentiment(line[0]) # convert to 1,0,-1
sentence = utilities.cleanString(line[1]) # lemmatize and stopwords
lines.append((sentiment, sentence)) # collect as a tuple
\end{verbatim}

\end{document}
