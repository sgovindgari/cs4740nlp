Notes on the project

1. Implement a collection of n-gram models
2. Specify responsibilities of each member

==Programming portion==
 1. Unsmoothed n-grams (COMPLETE BY BEN - might want to discuss parsing a little bit)
    Compute unsmoothed unigrams and bigrams
    Strip away labels and aggregate only text

    Bible - XML style - requires small amount of pre-processing
      Individual sentences in the Bible are separated by newlines

    Hotel review - process sentence boundaries with sentence segmentation tool.
      Include sentence boundaries as tokens
      Predict truthfulness of hotel reviews based on model

      IsTruthful and IsPositive - binary labels
      review - text of the review

      Predict review truthfulness and include a table that shows accuracy of the approach on the validation data

    ===Corpuses===
      King James Bible
      Hotel reviews from Amazon

 2. Random sentence generation (COMPLETE BY BEN)
    Code for generating random sentences based on unigram or bigram model
    Include examples of sentence generated by your sentence in part 1 submission
======================================================================================== (Part 1)
 3. Smoothing; unknown words (ANDY)
    Implement Good-Turing smoothing
      NOTES:
        self.uniques = list(set(self.corpus))
        tuples = list(itertools.product(*[self.uniques for _ in range(self.n - 1)]))
        # impossible. too much mem usage, paging to disk too much!
        N_0 is #wordsonce / total
        http://www.youtube.com/watch?v=XdjCCkFUBKU
      other notes: this is add-one:
      \[c^*\left(w_{n-1}w_n\right)
        =
        \frac {\left[C(w_{n-1}w_n) + 1\right] \times C(w_{n-1})}
              {C(w_{n-1}) + V}\]
      \[c^*_i
        = (c_i + 1) \frac{N}{N+V}\]
    Handle unknown words

 4. Perplexity (BEN)
    Implement code that computes perplexity
    Compute and report it

 5. Open ended extension (COMPLETE)
    Choose one (or more) of:
    - trigram/4-gram/n-gram (complete?)
    - smoothing (ANDY: linear interp)
    - interpolation
    - nontrivial unknown word handling
    - employ the language model in the service of another NLP or speech application
    - implement a modification that makes use of the validation set

 5.7 (not optional) - Hotel Review prediction (SPANDANA)

==Report (6 pages)==
  Contain every step of the programming portion
	- Describe your approach
	- Include relevant examples where appropriate
	- Include examples of random generator in action
	- indicate which smoothing you implemented
	- How you handled unknown words?
	- Discuss results of the perplexity experiments
	- Describe the extensions that you implemented and why
	- Can you perform any experiments that support the need for extension of change?
	- What experiments to show whether or not your extension has desired effect?

  Code
	- Include snippets with description of approach
	- Relevant portions of the code
	- Dont include irrelevant code
  Short section that explains how you divided up the work

Grading Guide
  10% - Part 1 submission: progress on unigram and bigram table algorithms
                           and random sentence generation
  10% - design and implementation
  05% - Random sentence generation
  25% - Extension
  50% - Report

================================================================================
The first 46 words in the bible corpus, represented in self.counts
  (24 distinct words = 24 unigrams)
  unigram: add 1 to all (unknowns?)
  bigram: add 1 to all (all unigrams. unknowns?)
  ..
[
{
  (): {
    'and': 5,
    'moved': 1,
    'deep': 1,
    'in': 1,
    'earth': 2,
    'darkness': 1,
    '<s>': 2,
    'god': 2,
    ',': 1,
    '.': 3,
    ';': 1,
    'was': 2,
    'waters': 1,
    'form': 1,
    'void': 1,
    'upon': 2,
    'beginning': 1,
    'spirit': 1,
    'heaven': 1,
    'created': 1,
    'of': 3,
    'face': 2,
    'without': 1,
    'the': 9
  }
}
,

{
  ('face',): {
    'of': 2
  },
  ('the',): {
    'heaven': 1,
    'waters': 1,
    'deep': 1,
    'face': 2,
    'earth': 2,
    'beginning': 1,
    'spirit': 1
  },
  ('in',): {
    'the': 1
  },
  ('heaven',): {
    'and': 1
  },
  ('void',): {
    ';': 1
  },
  ('upon',): {
    'the': 2
  },
  ('created',): {
    'the': 1
  },
  ('spirit',): {
    'of': 1
  },
  ('god',): {
    'moved': 1,
    'created': 1
  },
  ('form',): {
    ',': 1
  },
  (',',): {
    'and': 1
  },
  ('.',): {
    '<s>': 1,
    'and': 1
  },
  (';',): {
    'and': 1
  },
  ('was',): {
    'without': 1,
    'upon': 1
  },
  ('darkness',): {
    'was': 1
  },
  ('moved',): {
    'upon': 1
  },
  ('without',): {
    'form': 1
  },
  ('deep',): {
    '.': 1
  },
  ('earth',): {
    'was': 1,
    '.': 1
  },
  ('and',): {
    'the': 3,
    'void': 1,
    'darkness': 1
  },
  ('beginning',): {
    'god': 1
  },
  ('waters',): {
    '.': 1
  },
  ('<s>',): {
    'and': 1,
    'in': 1
  },
  ('of',): {
    'god': 1,
    'the': 2
  }
}

,

{
  ('of', 'the'): {
    'waters': 1,
    'deep': 1
  },
  ('and', 'the'): {
    'earth': 2,
    'spirit': 1
  },
  ('upon', 'the'): {
    'face': 2
  },
  ('the', 'waters'): {
    '.': 1
  },
  ('of', 'god'): {
    'moved': 1
  },
  ('form', ','): {
    'and': 1
  },
  ('earth', '.'): {
    '<s>': 1
  },
  ('darkness', 'was'): {
    'upon': 1
  },
  (',', 'and'): {
    'void': 1
  },
  ('<s>', 'in'): {
    'the': 1
  },
  ('<s>', 'and'): {
    'the': 1
  },
  ('the', 'beginning'): {
    'god': 1
  },
  ('and', 'darkness'): {
    'was': 1
  },
  ('was', 'without'): {
    'form': 1
  },
  ('face', 'of'): {
    'the': 2
  },
  ('deep', '.'): {
    'and': 1
  },
  ('earth', 'was'): {
    'without': 1
  },
  ('spirit', 'of'): {
    'god': 1
  },
  ('god', 'moved'): {
    'upon': 1
  },
  ('.', 'and'): {
    'the': 1
  },
  ('the', 'spirit'): {
    'of': 1
  },
  ('moved', 'upon'): {
    'the': 1
  },
  ('beginning', 'god'): {
    'created': 1
  },
  ('.', '<s>'): {
    'and': 1
  },
  ('and', 'void'): {
    ';': 1
  },
  ('the', 'face'): {
    'of': 2
  },
  ('the', 'deep'): {
    '.': 1
  },
  ('created', 'the'): {
    'heaven': 1
  },
  ('without', 'form'): {
    ',': 1
  },
  ('heaven', 'and'): {
    'the': 1
  },
  (';', 'and'): {
    'darkness': 1
  },
  ('the', 'heaven'): {
    'and': 1
  },
  ('in', 'the'): {
    'beginning': 1
  },
  ('void', ';'): {
    'and': 1
  },
  ('was', 'upon'): {
    'the': 1
  },
  ('the', 'earth'): {
    'was': 1,
    '.': 1
  },
  ('god', 'created'): {
    'the': 1
  }
}
]

For Hotel reviews we used the Punkt sentence segmentation tool provided by nltk library. Punkt has a tokenizer that divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences. We trained it on a large collection of plaintext in the target language before we used it. Punkt knows that the periods in Mr. Smith and Johann S. Bach do not mark sentence boundaries. And sometimes sentences can start with non-capitalized words. We made use of this sentence segmentation tool to recognize sentence boundaries. 

sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')

data = open('raw_reviews.train', 'w')
    for c in sents:
        # adds sentence start and end marker
         # write to file
        data.write(c+'<s> ')
    data.close()

After we performed sentence segmentation, we further added spaces around punctuation marks, floating dots like ..., and dashes like -- which were all treated as separate words. We also removed any XML and numbers IsTruthful and IsPositive.

edit = re.sub('(</?(TEXT|DOC)>\n)|([0-9]+,[0-9],)|((\.+\s){2,})', '', edit)
    edit = re.sub('\n|^', ' <s> ', edit)
    edit = re.sub('([,!?();:"-&/$])', r' \1 ', edit)
    edit = re.sub('(\.{1,})',r' \1 ', edit)
    edit = re.sub('--', ' -- ', edit)