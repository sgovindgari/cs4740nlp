%!TEX TS-program = pdflatex or xelatex
%!TEX encoding = UTF-8 Unicode

\documentclass{article}
\usepackage[letterpaper, margin=1in, left=0.75in, right=0.75in] {geometry}
\usepackage{microtype} % micro appearance
\usepackage[all]{nowidow} % no lone lines
\usepackage{changepage} % changes layout mid-page
\usepackage{enumitem} % enum (itemize, enumerate, description)
\usepackage{ifthen}
\usepackage{xfrac}
\usepackage{fancyhdr} % headers
\usepackage{amsmath} % matrices
\usepackage{amssymb} % symbols
\usepackage{gensymb} % symbols
\usepackage{tikz} % graphics?
\usepackage{bm} % bold math
\usepackage{multicol} % multiple columns
\usepackage{lipsum} % lipsum

\pagestyle{fancy}

\newcommand {\classname} {CS 4740/5740 -- Intro to Natural Language Processing}
\newcommand {\duedate} {Mon, February 24}
\newcommand {\hwtype} {Project}
\newcommand {\hwnum} {1: Language Modeling}
\newcommand {\innermargin} {0.15in} % indentation amt of nested lst

\let\tss\textsuperscript
\let\oldunderline\underline
\renewcommand\underline[1]{\oldunderline{\smash{#1}}}

\fancyhead[L] {\ifthenelse {\thepage=1}
  {bgs53, sg754, amw275\\
   Ben Shulman, Spandana Govindgari, Andy Wang}
  {\hwtype\ \hwnum\ (bgs53, sg754, amw275)}}
\fancyhead[R] {\ifthenelse {\thepage=1}
  {\classname\\\hwtype\ \hwnum\ (due \duedate)}
  {Page \thepage}}

\begin{document}
\begin{center}\textbf{Project 1 Report on Language Modeling}\end{center}

All our code is written in Python. We use several libraries, including the nltk platform's punkt for preprocessing.\par

\section{Unsmoothed ngrams}

\subsection{Bible Parsing}

We began by writing a parser for 

\subsection{Hotel Review Parsing}

\subsection{unsmoothed ngram}

Our preprocessing code for both corpuses (King James Bible and Hotel Reviews) is in \texttt{preprocessCorpus.py}.\par

Before we inputted the training data for both corpuses into our ngram implementation, we wrote a script to preprocess them, removing extraneous xml-like tags, numbers, etc. For the bible corpus, our sentences are split on Bible verses of the format \texttt{[0-9]+:[0-9]+}. Ben and Spandana has written much of the preprocessor for the Bible and Hotel corpuses respectively.\par

For our ngram model, we initially began by individually creating unigram and bigram classes, but decided that there was already much in common between the two systems, so an abstraction was not too hard to make. Hence we went immediately to an n-gram model. Our ngram class reads in the preprocessed sources, ignores case, and splits the text at spaces.\par

Our storage is a list of dictionaries, each of which store unigram/bigram/trigram/etc data. The dictionaries record counts of the $p$ previous words followed by a word, i.e.\ for a bigram model, it stores the unigram counts and bigram counts. Each dictionary then holds an entry (another lookup table) for each tuple of previous words, i.e.\ for unigram there is only one entry: \texttt{[((), [(the,5),(a,6),(cat,2),...])]}. For bigram, there would be \texttt{[('the',[('cat', 3),('dog', 4),...]),('a',[(cow, 2),(horse, 1),...]),...]}\par

Our ngram steps through the corpus word-by-word, and accumulate a list of previous words (no longer than $n$) to use as a lookup. After this has been set, an optional smoothing algorithm (like add-one, or Good-Turing) follows. Probabilities are calculated last by going over every row of counts and calculating the conditional probabilities for each row.\par

[talk about responsibilities and files here]

[examples]

\subsection{Hotel reviews}
For Hotel reviews we used the Punkt sentence segmentation tool provided by nltk library. Punkt has a tokenizer that divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences. We trained it on a large collection of plaintext in the target language before we used it. Punkt knows that the periods in Mr. Smith and Johann S. Bach do not mark sentence boundaries. And sometimes sentences can start with non-capitalized words. We made use of this sentence segmentation tool to recognize sentence boundaries. 

\section{Random sentence generation}
To generate a random sentence we start with a sentence start marker. We then generate a random float (0 to 1)
and then simply traverse the appropriate row of our probability table until we reach the appropriate accumulated probability and output that word.\par

We continue to generate words until we generate another sentence segmentation marker.

[Include examples of generator in action!]

\iffalse
\vspace{2mm}
\setlength{\parindent}{0cm}
\newcommand\npar{\par\smallskip}
Sample unigram sentences for the bible corpus:\npar
\texttt{<s> after ramah and , of . lord , shall this that every burnt land his my that the now all lord jabin's and few at flesh is waved he thou they of watered hath wife the unto gilead a stones might ; for ; the eliezer even above cherethites said the go of and ; that they family precious <s>}\npar
\texttt{<s> keep sin <s>}\npar
\texttt{<s> altar things ; and , : , three bags the which abraham : shall made his begat word saying snare we your i <s>}\npar
\texttt{<s> , <s>}\npar
\texttt{<s> children <s>}\npar
\bigskip

Sample bigram sentences for the bible corpus:\npar
\texttt{<s> for ashtoreth the son . <s>}\npar
\texttt{<s> david my father's house , the wheat and all the god hath sent messengers , from dophkah . <s>}\npar
\texttt{<s> and burned the land cast them , i will heal : make thee ? and the month was six hundred and the place . <s>}\npar
\texttt{<s> and thou hast found stealing any of the egyptians shall wash with him to eziongeber . <s>}\npar
\texttt{<s> beware . <s>}\npar
\bigskip

Sample unigram sentences for the hotel reviews corpus:\npar
\texttt{<s> i the ; linens . were able and our <s>}\npar
\texttt{<s> use from book fine at <s>}\npar
\texttt{<s> could said ranges smooth that course the phone expressed the its to minutes it because ; i'm we at it blamed ; <s>}\npar
\texttt{<s> faint coffee can the request were . chicago pillows fantastic intercontinental there . the the <s>}\npar
\texttt{<s> i've . mattress . at leisure a already centrally chicago don't an seem you they to the the or i booked great the find bothered time " . .... of . also above the on it . to explain my really the was online . will sub air ; good peace charge <s>}\npar
\bigskip

Sample bigram sentences for the hotel reviews corpus:\npar
\texttt{<s> we arrived at in my little lost and advertised as inside and we did inquire whether hard with this hotel in the services . <s>}\npar
\texttt{<s> we were not want or phone system " stains ; and could not a dirty and ready for business and the 10th floor ; and if you can hear they had earplugs . <s>}\npar
\texttt{<s> prior guest . <s>}\npar
\texttt{<s> there are typical - when reviewing my girlfriend are 21st century standards . <s>}\npar
\texttt{<s> the entire stay because its a room was pleased that can expect from the past the beautiful decor is saying that price . <s>}\npar

\fi

\section{Smoothing and unknown word handling}
\lipsum[4]

\section{Perplexity}
\lipsum[4]

\section{Extensions}

\subsection{Generalized n-gram}

\subsection{Backoff}

\subsection{Add-One Smoothing}

\subsection{Right-to-Left n-grams}

\section{Further extensions and possibilities}
Can you perform any experiments that support the need for extension of change? (trigram backing off?)\par
What experiments to show whether or not your extension has desired effect?\par
\lipsum[4]

\section{Division of work}
\lipsum[4]

\end{document}
